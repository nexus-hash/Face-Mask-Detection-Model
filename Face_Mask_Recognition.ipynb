{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Mask Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaijH2t+mjTD8JF8Yr31yg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5lNtGyYXipo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b240d560-22f4-4585-c6d1-5a7c6ff64f3a"
      },
      "source": [
        "import cv2,os\n",
        "data_path='dataset/dataset'\n",
        "data_categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(data_categories))]\n",
        "label_dict=dict(zip(data_categories,labels))\n",
        "print(label_dict)\n",
        "print(data_categories)\n",
        "print(labels)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'with_mask': 0, 'without_mask': 1}\n",
            "['with_mask', 'without_mask']\n",
            "[0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iumtUJ3Yxa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 120\n",
        "image_data=[]\n",
        "target=[]\n",
        "\n",
        "for data_category in data_categories:\n",
        "  folder_path=os.path.join(data_path,data_category)\n",
        "  image_names=os.listdir(folder_path)\n",
        "\n",
        "  for image_name in image_names:\n",
        "    image_path=os.path.join(folder_path,image_name)\n",
        "    image=cv2.imread(image_path)\n",
        "\n",
        "    try:\n",
        "      #Converting image to a single color i.e gray scale\n",
        "      gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "      #resizing a image to size 120x120 since we need a fixed size for all image to work on\n",
        "      resized=cv2.resize(gray,(image_size,image_size))\n",
        "      image_data.append(resized)\n",
        "      #appending the image and the label(categorized) into the list\n",
        "      target.append(label_dict[data_category])\n",
        "\n",
        "      #While parsing through images if any image is not found or anything else exception is generated\n",
        "      #It gets caught and without stopping the loop it continnues to the next image\n",
        "    except Exception as k:\n",
        "      print('Exception:',k)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J00_d1LOcAQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "image_data=np.array(image_data)/255.0\n",
        "image_data=np.reshape(image_data,(image_data.shape[0],image_size,image_size,1))\n",
        "target=np.array(target)\n",
        "\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "target= np_utils.to_categorical(target)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnKDn-nAhTEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "#1st Convolutional layer\n",
        "model.add(Conv2D(200,(3,3),input_shape=image_data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#2nd Convolutional layer\n",
        "model.add(Conv2D(100,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Flattening Layer to stack the output from the 2nd Convolutional layer\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "#Final layer with two output for 2 categories\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-WY_c6Emg97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data,test_data,train_target,test_target=train_test_split(image_data,target,test_size=0.1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ah6ktyrm5qc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "1abde49b-5bfd-4ad3-a584-d7e4fab560c9"
      },
      "source": [
        "history=model.fit(train_data,train_target,epochs=20,validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "87/87 [==============================] - 316s 4s/step - loss: 0.6895 - accuracy: 0.5970 - val_loss: 0.6025 - val_accuracy: 0.6565\n",
            "Epoch 2/20\n",
            "87/87 [==============================] - 320s 4s/step - loss: 0.5747 - accuracy: 0.7024 - val_loss: 0.5608 - val_accuracy: 0.7420\n",
            "Epoch 3/20\n",
            "87/87 [==============================] - 315s 4s/step - loss: 0.5430 - accuracy: 0.7191 - val_loss: 0.4985 - val_accuracy: 0.7580\n",
            "Epoch 4/20\n",
            "87/87 [==============================] - 315s 4s/step - loss: 0.3971 - accuracy: 0.8246 - val_loss: 0.3264 - val_accuracy: 0.8623\n",
            "Epoch 5/20\n",
            "87/87 [==============================] - 316s 4s/step - loss: 0.2953 - accuracy: 0.8782 - val_loss: 0.2933 - val_accuracy: 0.8797\n",
            "Epoch 6/20\n",
            "87/87 [==============================] - 314s 4s/step - loss: 0.2486 - accuracy: 0.8949 - val_loss: 0.3207 - val_accuracy: 0.8638\n",
            "Epoch 7/20\n",
            "87/87 [==============================] - 320s 4s/step - loss: 0.2083 - accuracy: 0.9177 - val_loss: 0.2822 - val_accuracy: 0.8812\n",
            "Epoch 8/20\n",
            "87/87 [==============================] - 314s 4s/step - loss: 0.1741 - accuracy: 0.9286 - val_loss: 0.2793 - val_accuracy: 0.8957\n",
            "Epoch 9/20\n",
            "87/87 [==============================] - 318s 4s/step - loss: 0.1417 - accuracy: 0.9435 - val_loss: 0.2492 - val_accuracy: 0.9029\n",
            "Epoch 10/20\n",
            "87/87 [==============================] - 315s 4s/step - loss: 0.1183 - accuracy: 0.9594 - val_loss: 0.3130 - val_accuracy: 0.8971\n",
            "Epoch 11/20\n",
            "87/87 [==============================] - 317s 4s/step - loss: 0.0963 - accuracy: 0.9638 - val_loss: 0.3257 - val_accuracy: 0.8812\n",
            "Epoch 12/20\n",
            "87/87 [==============================] - 314s 4s/step - loss: 0.1063 - accuracy: 0.9580 - val_loss: 0.2951 - val_accuracy: 0.9029\n",
            "Epoch 13/20\n",
            "87/87 [==============================] - 318s 4s/step - loss: 0.0799 - accuracy: 0.9692 - val_loss: 0.2759 - val_accuracy: 0.9203\n",
            "Epoch 14/20\n",
            "87/87 [==============================] - 315s 4s/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 0.3016 - val_accuracy: 0.9101\n",
            "Epoch 15/20\n",
            "87/87 [==============================] - 319s 4s/step - loss: 0.0524 - accuracy: 0.9801 - val_loss: 0.3105 - val_accuracy: 0.9014\n",
            "Epoch 16/20\n",
            "87/87 [==============================] - 315s 4s/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.3293 - val_accuracy: 0.9072\n",
            "Epoch 17/20\n",
            "87/87 [==============================] - 317s 4s/step - loss: 0.0481 - accuracy: 0.9819 - val_loss: 0.3107 - val_accuracy: 0.9145\n",
            "Epoch 18/20\n",
            "87/87 [==============================] - 314s 4s/step - loss: 0.0485 - accuracy: 0.9859 - val_loss: 0.3428 - val_accuracy: 0.9000\n",
            "Epoch 19/20\n",
            "87/87 [==============================] - 320s 4s/step - loss: 0.0406 - accuracy: 0.9859 - val_loss: 0.3666 - val_accuracy: 0.9087\n",
            "Epoch 20/20\n",
            "87/87 [==============================] - 314s 4s/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.3435 - val_accuracy: 0.9087\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}